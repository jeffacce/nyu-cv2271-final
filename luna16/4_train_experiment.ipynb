{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aefaad7-4d51-4b8e-a9d0-4592ae839d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "from datasets import LUNA16DatasetFromIso, LUNA16DatasetFromCubes\n",
    "from models import Classifier3D, TinyClassifier\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from losses import binary_focal_loss_with_logits\n",
    "import itertools\n",
    "from timeit import default_timer as dt\n",
    "\n",
    "\n",
    "# linearly transform [-1000, 400] to [0, 1]\n",
    "def linear_transform_to_0_1(X, min=-1000, max=400):\n",
    "    result = torch.clamp(X, min=min, max=max)\n",
    "    result = result - min\n",
    "    result = result / (max - min)\n",
    "    return result\n",
    "\n",
    "\n",
    "def calc_confusion(pred_bool, target_bool):\n",
    "    not_pred_bool = ~pred_bool\n",
    "    not_target_bool = ~target_bool\n",
    "    tp = (pred_bool & target_bool).sum().item()\n",
    "    tn = (not_pred_bool & not_target_bool).sum().item()\n",
    "    fp = (pred_bool & not_target_bool).sum().item()\n",
    "    fn = (not_pred_bool & target_bool).sum().item()\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "\n",
    "def shuffle_wrapper(x):\n",
    "    np.random.shuffle(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31b4e2a2-eb74-4fae-b8f1-9491ead36489",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "# batch size must be even since we sample half positives, half negatives\n",
    "assert BATCH_SIZE % 2 == 0\n",
    "\n",
    "# one epoch is defined as one pass through all negative samples;\n",
    "# positive samples are reused\n",
    "EPOCHS = 50\n",
    "MOMENTUM = 0.9\n",
    "LR = 0.003\n",
    "WEIGHT_DECAY = 1e-4\n",
    "LOG_INTERVAL = 100\n",
    "SHOULD_AUGMENT = True\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052f9f36-0940-4d6f-a395-51ac61f45da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Classifier3D(in_channels=1, img_size=48).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a3bcb1d-8fc9-4e9a-9bf4-5344c918eb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8aa573b-f8a3-4e4d-8d24-b479e5668b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_subsets = [\n",
    "    'subset0',\n",
    "    'subset1',\n",
    "    'subset2',\n",
    "    'subset3',\n",
    "    'subset4',\n",
    "    'subset5',\n",
    "]\n",
    "val_subsets = [\n",
    "    'subset6',\n",
    "    'subset7',\n",
    "]\n",
    "test_subsets = [\n",
    "    'subset8',\n",
    "    'subset9',\n",
    "]\n",
    "\n",
    "train_neg_dataset = LUNA16DatasetFromIso(\n",
    "    iso_root_path='/scratch/zc2357/cv/final/datasets/luna16_iso/',\n",
    "    candidates_file='candidates_V2.csv',\n",
    "    subsets=train_subsets,\n",
    ")\n",
    "train_pos_dataset = LUNA16DatasetFromCubes(\n",
    "    cube_root_path='/scratch/zc2357/cv/final/datasets/luna16_cubes',\n",
    "    candidates_file='candidates_V2_subindexed.csv',\n",
    "    subsets=train_subsets,\n",
    ")\n",
    "val_dataset = LUNA16DatasetFromIso(\n",
    "    iso_root_path='/scratch/zc2357/cv/final/datasets/luna16_iso/',\n",
    "    candidates_file='candidates_V2.csv',\n",
    "    subsets=val_subsets,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "151d5511-5c33-485d-b9ce-a713267a7633",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos_dataloader = DataLoader(\n",
    "    train_pos_dataset,\n",
    "    batch_size=BATCH_SIZE//2,\n",
    "    sampler=SubsetRandomSampler(train_pos_dataset.pos_sample_idx),\n",
    "    num_workers=1,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,  # validation set uses cached arrays to save disk hits\n",
    "    num_workers=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f95be0f3-5f28-41e6-8d54-12dde996c22a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
    "writer = SummaryWriter(comment='_profiling_baseline_UNet3D3x3_randomFlipsPosNeg_focalLoss_weightDecay1e-4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fb2ac71-3220-40cf-947b-517527bc19df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "neg: 0.55\n",
      "pos: 0.00\n",
      "aug/proc: 0.15\n",
      "forward: 1.10\n",
      "backward: 0.03\n",
      "train_loss_mean: 0.41\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "Train Epoch: 1 [0/452829 (0%)]\tLoss: 0.088669\t94\t44\t84\t34\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.60\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.13\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.60\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.60\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.11\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.60\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.60\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.60\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.23\n",
      "aug/proc: 0.09\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.60\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.60\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.05\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.60\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.10\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.60\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.01\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.60\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.13\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.60\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.25\n",
      "aug/proc: 0.09\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.60\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.01\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.13\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.07\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.24\n",
      "aug/proc: 0.08\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.13\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.01\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.11\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.60\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.11\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.08\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.24\n",
      "aug/proc: 0.08\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.08\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.01\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.01\n",
      "aug/proc: 0.15\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.10\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.13\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.24\n",
      "aug/proc: 0.09\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.01\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.13\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.60\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.01\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.24\n",
      "aug/proc: 0.11\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.16\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.01\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.01\n",
      "aug/proc: 0.14\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.00\n",
      "aug/proc: 0.11\n",
      "forward: 0.03\n",
      "backward: 0.01\n",
      "train_loss_mean: 0.61\n",
      "pred_y_bool: 0.00\n",
      "train_y_bool: 0.00\n",
      "confusion: 0.00\n",
      "confusion_add: 0.00\n",
      "misc: 0.00\n",
      "neg: 0.00\n",
      "pos: 0.23\n",
      "aug/proc: 0.09\n",
      "forward: 0.03\n",
      "backward: 0.01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/state/partition1/job-12742038/ipykernel_1883458/4163724562.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mtrain_loss_mean\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_loss_mean: %.2f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =========== TRAINING ===========\n",
    "pos_epoch = 1  # how many times we've gone through the positive samples\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "    # reshuffle negative dataloader every epoch\n",
    "    neg_idx_shuffled = (\n",
    "        train_neg_dataset.candidates.loc[train_neg_dataset.neg_sample_idx]\n",
    "        .copy().reset_index()\n",
    "        .groupby('seriesuid')['index'].unique()\n",
    "        .apply(shuffle_wrapper)  # shuffle within cases\n",
    "        .apply(list)\n",
    "    )\n",
    "    neg_idx_shuffled = neg_idx_shuffled.sample(len(neg_idx_shuffled))      # shuffle case order\n",
    "    neg_idx_shuffled = list(itertools.chain.from_iterable(neg_idx_shuffled.values))  # flatten\n",
    "\n",
    "    train_neg_dataloader = DataLoader(\n",
    "        train_neg_dataset,\n",
    "        batch_size=BATCH_SIZE//2,\n",
    "        shuffle=False,\n",
    "        sampler=neg_idx_shuffled,\n",
    "        num_workers=1,\n",
    "    )\n",
    "\n",
    "    model.train()\n",
    "    print('Epoch %s' % epoch)\n",
    "    train_pos_dataiter = iter(train_pos_dataloader)\n",
    "    train_loss_mean = 0\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    start = dt()\n",
    "    for batch_idx, (neg_X, neg_y) in enumerate(train_neg_dataloader):\n",
    "        print('neg: %.2f' % (dt() - start))\n",
    "        start = dt()\n",
    "        optimizer.zero_grad()\n",
    "        try:\n",
    "            should_write = False\n",
    "            pos_X, pos_y = next(train_pos_dataiter)\n",
    "        except StopIteration:\n",
    "            train_pos_dataiter = iter(train_pos_dataloader)\n",
    "            pos_X, pos_y = next(train_pos_dataiter)\n",
    "            \n",
    "            pos_epoch += 1\n",
    "            should_write = True\n",
    "        print('pos: %.2f' % (dt() - start))\n",
    "        start = dt()\n",
    "\n",
    "        neg_X = neg_X.reshape(-1, 1, 48, 48, 48)\n",
    "        train_X = torch.cat([pos_X, neg_X])\n",
    "        train_y_cpu = torch.cat([pos_y, neg_y]).reshape(-1, 1).float()\n",
    "\n",
    "        train_X = linear_transform_to_0_1(train_X, min=-1000, max=400)\n",
    "        \n",
    "        if SHOULD_AUGMENT:\n",
    "            flip_dims = []\n",
    "            flip_x = (np.random.randint(0, 2) == 1)\n",
    "            flip_y = (np.random.randint(0, 2) == 1)\n",
    "            flip_z = (np.random.randint(0, 2) == 1)\n",
    "\n",
    "            if flip_x:\n",
    "                flip_dims.append(2)\n",
    "            if flip_y:\n",
    "                flip_dims.append(3)\n",
    "            if flip_z:\n",
    "                flip_dims.append(4)\n",
    "            if len(flip_dims) > 0:\n",
    "                train_X = torch.flip(train_X, flip_dims)\n",
    "        \n",
    "        print('aug/proc: %.2f' % (dt() - start))\n",
    "        start = dt()\n",
    "        \n",
    "        train_X = train_X.to(device)\n",
    "        train_y = train_y_cpu.to(device)\n",
    "        \n",
    "        pred_y = model(train_X)\n",
    "        \n",
    "        print('forward: %.2f' % (dt() - start))\n",
    "        start = dt()\n",
    "\n",
    "        loss = binary_focal_loss_with_logits(pred_y, train_y, reduction='mean')\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print('backward: %.2f' % (dt() - start))\n",
    "        start = dt()\n",
    "        \n",
    "        train_loss_mean += loss.sum().cpu().item()\n",
    "        \n",
    "        print('train_loss_mean: %.2f' % (dt() - start))\n",
    "        start = dt()\n",
    "        \n",
    "        pred_y_bool = (torch.sigmoid(pred_y.cpu()) > 0.5).cpu()\n",
    "        \n",
    "        print('pred_y_bool: %.2f' % (dt() - start))\n",
    "        start = dt()\n",
    "        \n",
    "        train_y_bool = (train_y_cpu == 1)\n",
    "        \n",
    "        print('train_y_bool: %.2f' % (dt() - start))\n",
    "        start = dt()\n",
    "        \n",
    "        this_tp, this_tn, this_fp, this_fn = calc_confusion(pred_y_bool, train_y_bool)\n",
    "        \n",
    "        print('confusion: %.2f' % (dt() - start))\n",
    "        start = dt()\n",
    "        \n",
    "        tp += this_tp\n",
    "        tn += this_tn\n",
    "        fp += this_fp\n",
    "        fn += this_fn\n",
    "        \n",
    "        print('confusion_add: %.2f' % (dt() - start))\n",
    "        start = dt()\n",
    "        \n",
    "        if batch_idx % LOG_INTERVAL == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\t{:.0f}\\t{:.0f}\\t{:.0f}\\t{:.0f}'.format(\n",
    "                epoch, batch_idx * len(neg_X), len(train_neg_dataloader.dataset),\n",
    "                100. * batch_idx / len(train_neg_dataloader), loss.item(), this_tp, this_tn, this_fp, this_fn))\n",
    "\n",
    "        if should_write:\n",
    "            writer.add_scalar('loss/train', train_loss_mean / len(train_pos_dataloader), pos_epoch)\n",
    "            writer.add_scalar('accuracy/train', 100. * (tp + tn) / (tp + fp + tn + fn), pos_epoch)\n",
    "            try:\n",
    "                writer.add_scalar('precision/train', 100. * (tp / (tp + fp)), pos_epoch)\n",
    "            except ZeroDivisionError:\n",
    "                writer.add_scalar('precision/train', -1, pos_epoch)\n",
    "            try:\n",
    "                writer.add_scalar('recall/train', 100. * (tp / (tp + fn)), pos_epoch)\n",
    "            except ZeroDivisionError:\n",
    "                writer.add_scalar('recall/train', -1, pos_epoch)\n",
    "            train_loss_mean = 0\n",
    "            tp = 0\n",
    "            tn = 0\n",
    "            fp = 0\n",
    "            fn = 0\n",
    "            \n",
    "        print('misc: %.2f' % (dt() - start))\n",
    "        start = dt()\n",
    "    \n",
    "    # VALIDATION\n",
    "    print('Validation')\n",
    "    model.eval()\n",
    "    tp = 0\n",
    "    tn = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    \n",
    "    for batch_idx, (X, y) in enumerate(val_dataloader):\n",
    "        X = X.reshape(-1, 1, 48, 48, 48).float()\n",
    "        y = y.reshape(-1, 1).float()\n",
    "        X = X.to(device)\n",
    "        y = y.to(device)\n",
    "        pred_y = model(X)\n",
    "        \n",
    "        pred_y_bool = torch.sigmoid(pred_y) > 0.5\n",
    "        y_bool = (y == 1)\n",
    "        this_tp, this_tn, this_fp, this_fn = calc_confusion(pred_y_bool, y_bool)\n",
    "        \n",
    "        tp += this_tp\n",
    "        tn += this_tn\n",
    "        fp += this_fp\n",
    "        fn += this_fn\n",
    "    \n",
    "    writer.add_scalar('accuracy/val', 100. * (tp + tn) / (tp + fp + tn + fn), epoch)\n",
    "    writer.add_scalar('tp/val', tp, epoch)\n",
    "    writer.add_scalar('fp/val', fp, epoch)\n",
    "    writer.add_scalar('tn/val', tn, epoch)\n",
    "    writer.add_scalar('fn/val', fn, epoch)\n",
    "    try:\n",
    "        writer.add_scalar('precision/val', 100. * (tp / (tp + fp)), epoch)\n",
    "    except ZeroDivisionError:\n",
    "        writer.add_scalar('precision/val', -1, epoch)\n",
    "    try:\n",
    "        writer.add_scalar('recall/val', 100. * (tp / (tp + fn)), epoch)\n",
    "    except ZeroDivisionError:\n",
    "        writer.add_scalar('recall/val', -1, epoch)\n",
    "    \n",
    "    model_savepath = (Path(writer.get_logdir()) / f'epoch_{epoch}.pth').as_posix()\n",
    "    torch.save(model.state_dict(), model_savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8faae6e-de80-4123-a104-f90421850e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
